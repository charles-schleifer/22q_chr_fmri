---
title: "22q fMRI analysis"
author: "C. Schleifer"
date: "2022-09-30"
output: html_document
---

# setup workspace
```{r setup, message=FALSE, warning=FALSE, paged.print=FALSE}
# function to set up environment
# clear workspace
rm(list = ls(all.names = TRUE))

# use SSHFS to mount hoffman2 server (download SSHFS for mac: https://osxfuse.github.io/)
# TODO: set hoffman2 username
uname <- "schleife"
# set local path to mount server
hoffman <- "~/Desktop/hoffman_mount"
# create directory if needed 
# if(!file.exists(hoffman)){dir.create(hoffman)}
# make string to run as system command
mntcommand <- paste0("umount -f ", hoffman,"; sshfs ",uname,"@hoffman2.idre.ucla.edu:/u/project/cbearden/data ",hoffman)
# if hoffman directory is empty, use system command and sshfs to mount server, if not empty assume already mounted and skip
if(length(list.files(hoffman)) == 0){system(mntcommand)}else{print(paste(hoffman,"is not empty...skipping SSHFS step"))}

# list packages to load
packages <- c("devtools","conflicted","here","magrittr", "dplyr", "tidyr","readxl", "ggplot2","gghalves","patchwork", "ggrepel", "ggpubr", "gt", "scico", "RColorBrewer", "ciftiTools", "tableone", "data.table", "reshape2", "neuroCombat", "pls")

# install packages if not yet installed
all_packages <- rownames(installed.packages())
installed_packages <- packages %in% all_packages
if (any(installed_packages == FALSE)){install.packages(packages[!installed_packages])}

# load packages
invisible(lapply(packages, library, character.only = TRUE))

# install neuroComBat from github 
# https://github.com/Jfortin1/neuroCombat_Rpackage
#install_github("jfortin1/neuroCombatData")
#install_github("jfortin1/neuroCombat_Rpackage")

# use the filter function from dplyr, not stats
conflict_prefer("filter", "dplyr")

# get path to project repo directory
project <- here()
print(paste("Project directory:", project))

# set up connectome workbench path for ciftiTools
# https://www.humanconnectome.org/software/get-connectome-workbench
# local wbpath (edit this path if workbench is installed in another location, e.g. on hoffman: /u/project/CCN/apps/hcp/current/workbench/bin_rh_linux64/)
# TODO: edit if necessary
wbpath <- "/Applications/workbench/bin_macosx64/"
ciftiTools.setOption("wb_path", wbpath)

# load rgl for ciftiTools visualization
# may require XQartz v2.8.1 to be installed locally
if(!require('rgl', quietly=TRUE)){install.packages('rgl')}
rgl::setupKnitr()
rgl::rgl.open(); rgl::rgl.close()

# set to TRUE to save outputs, otherwise won't save
# TODO: change output names 
save_outputs=FALSE

# load Rdata instead of loading individual files
# load(file.path(project,"demographics/22q_chr_fmri_init_ctx.Rdata"))
# load(file.path(project,"git_exclude/22q_chr_fmri_main.Rdata"))
# load(file.path(project,"git_exclude/22q_chr_fmri_full.Rdata"))
```

get subject IDs and load demographic data
```{r loadDemo}
# load CAB-NP network parcellation
# https://github.com/ColeLab/ColeAnticevicNetPartition
ji_key <- read.table(file.path(project,"CAB-NP/CortexSubcortex_ColeAnticevic_NetPartition_wSubcorGSR_parcels_LR_LabelKey.txt"),header=T)
ji_net_keys <- ji_key[,c("NETWORKKEY","NETWORK")] %>% distinct %>% arrange(NETWORKKEY)
# read cifti with subcortical structures labeled 
xii_Ji_parcel <- read_cifti(file.path(project,"CAB-NP/CortexSubcortex_ColeAnticevic_NetPartition_wSubcorGSR_parcels_LR.dscalar.nii"), brainstructures = "all")
xii_Ji_network <- read_cifti(file.path(project,"CAB-NP/CortexSubcortex_ColeAnticevic_NetPartition_wSubcorGSR_netassignments_LR.dscalar.nii"), brainstructures = "all")
# read only surface parcels
xii_Ji_parcel_surf <- read_cifti(file.path(project,"CAB-NP/CortexSubcortex_ColeAnticevic_NetPartition_wSubcorGSR_parcels_LR.dscalar.nii"), brainstructures = c("left", "right"))

# paths to sessions directories
trio_dir <- file.path(hoffman,"22q/qunex_studyfolder/sessions")
prisma_dir <- file.path(hoffman,"22qPrisma/qunex_studyfolder/sessions")
suny_dir <- file.path(hoffman,"Enigma/SUNY/qunex_studyfolder/sessions")
rome_dir <- file.path(hoffman,"Enigma/Rome/qunex_studyfolder/sessions")
iop_dir <- file.path(hoffman,"Enigma/IoP/qunex_studyfolder/sessions")
napls_dir <- file.path(hoffman,"NAPLS_BOLD/NAPLS2/sessions/S_sessions/")

# get list of sessions
trio_sessions <- list.files(trio_dir,pattern="Q_[0-9]")
trio_sessions <- c("Q_0001_09242012", "Q_0001_10152010", "Q_0005_04182011", "Q_0007_04012011", "Q_0009_09292011", "Q_0016_03292011", "Q_0016_10082012", "Q_0020_03262012", "Q_0020_05052011", "Q_0021_01132011", "Q_0021_11052012", "Q_0024_04152011", "Q_0024_09212012", "Q_0026_03232012", "Q_0026_05032013", "Q_0033_03192010", "Q_0036_03302010", "Q_0036_06212012", "Q_0036_06282011", "Q_0037_04202011", "Q_0038_06042010", "Q_0039_04132010", "Q_0039_06012011", "Q_0041_09262012", "Q_0045_07132010", "Q_0045_08302011", "Q_0045_10052012", "Q_0051_01302012", "Q_0052_07302010", "Q_0053_08022010", "Q_0053_12212012", "Q_0054_08062010", "Q_0056_08252010", "Q_0056_09102012", "Q_0059_08032011", "Q_0062_11302011", "Q_0076_10212010", "Q_0077_02292012", "Q_0077_03112013", "Q_0077_10252010", "Q_0078_11102011", "Q_0080_11222010", "Q_0081_11242010", "Q_0082_01062012", "Q_0082_01112013", "Q_0082_12162010", "Q_0085_02242012", "Q_0091_03052012", "Q_0091_03072011", "Q_0092_03102011", "Q_0093_03082011", "Q_0093_03122012", "Q_0093_03122013", "Q_0098_04012011", "Q_0099_04012011", "Q_0100_04082011", "Q_0101_01032013", "Q_0101_04122011", "Q_0102_01032013", "Q_0102_04122011", "Q_0103_04182011", "Q_0103_08272012", "Q_0105_05022011", "Q_0109_05262011", "Q_0112_11142012", "Q_0114_11092012", "Q_0117_07062011", "Q_0117_08312012", "Q_0118_07072011", "Q_0124_07292011", "Q_0124_09172012", "Q_0127_03052013", "Q_0127_08012014", "Q_0127_08082011", "Q_0130_08132012", "Q_0130_08162011", "Q_0130_11042014", "Q_0132_08222011", "Q_0135_09012011", "Q_0141_10072013", "Q_0141_10092012", "Q_0146_11082012", "Q_0146_12072011", "Q_0147_08112015", "Q_0147_08142014", "Q_0147_12122011", "Q_0149_11192012", "Q_0149_12192011", "Q_0150_11192012", "Q_0150_12202011", "Q_0151_01122012", "Q_0153_01202012", "Q_0156_01312012", "Q_0156_12102013", "Q_0157_01312012", "Q_0159_02122013", "Q_0161_03012012", "Q_0161_04192013", "Q_0162_03202012", "Q_0163_03262012", "Q_0166_01092014", "Q_0166_04052012", "Q_0168_04052012", "Q_0169_04062012", "Q_0170_04102012", "Q_0170_11252014", "Q_0171_04102012", "Q_0171_11252014", "Q_0172_04122012", "Q_0172_04262013", "Q_0173_04122012", "Q_0173_04172014", "Q_0173_04262013", "Q_0174_04182012", "Q_0174_04272015", "Q_0176_04242012", "Q_0176_05072013", "Q_0177_05012012", "Q_0178_05012012", "Q_0182_05182012", "Q_0184_05242012", "Q_0185_05242012", "Q_0186_04092015", "Q_0188_05242012", "Q_0189_05242012", "Q_0190_06012012", "Q_0190_08132013", "Q_0196_06192015", "Q_0196_06202012", "Q_0196_09122013", "Q_0200_04032015", "Q_0200_08052013", "Q_0213_08032012", "Q_0215_08062012", "Q_0215_08172015", "Q_0216_08062012", "Q_0216_08172015", "Q_0217_01142014", "Q_0217_02042015", "Q_0217_08092012", "Q_0219_08122014", "Q_0219_08162012", "Q_0219_09012015", "Q_0222_08212012", "Q_0223_08212012", "Q_0227_10032012", "Q_0228_01292014", "Q_0228_09272012", "Q_0229_10022012", "Q_0232_12122012", "Q_0234_03252014", "Q_0234_12132012", "Q_0236_03072013", "Q_0238_03202013", "Q_0238_08042014", "Q_0238_11132015", "Q_0240_03232015", "Q_0240_03272013", "Q_0240_06262014", "Q_0242_03272013", "Q_0242_05162016", "Q_0244_09162013", "Q_0244_09232014", "Q_0246_09242013", "Q_0252_12102013", "Q_0255_10212014", "Q_0260_06092014", "Q_0260_10262015", "Q_0266_08122014", "Q_0268_10132014", "Q_0269_10142014", "Q_0277_12082014", "Q_0284_03182015", "Q_0285_03182015", "Q_0286_03182015", "Q_0291_04172015", "Q_0307_10132015", "Q_0310_11182015", "Q_0311_12082015", "Q_0315_01262016", "Q_0321_03232016", "Q_0322_03312016", "Q_0326_04142016", "Q_0327_04142016")
#prisma_sessions <- list.files(prisma_dir,pattern="Q_[0-9]")
prisma_sessions <- c("Q_0005_11072017", "Q_0017_10022017", "Q_0019_03022020", "Q_0036_08082017", "Q_0036_08312018", "Q_0036_09302019", "Q_0037_08152017", "Q_0041_10092017", "Q_0051_02032017", "Q_0105_03112020", "Q_0105_12032018", "Q_0114_12052017", "Q_0141_06122018", "Q_0141_08052019", "Q_0147_12112017", "Q_0147_12112018", "Q_0196_01082020", "Q_0213_05012017", "Q_0217_01242017", "Q_0217_02192020", "Q_0235_05252017", "Q_0238_02202018", "Q_0240_09192017", "Q_0240_11162018", "Q_0246_10092018", "Q_0246_10102017", "Q_0246_10142016", "Q_0260_06192017", "Q_0260_06242019", "Q_0260_06252018", "Q_0263_02252019", "Q_0263_02262018", "Q_0263_11072016", "Q_0271_10182016", "Q_0277_12132016", "Q_0278_11292017", "Q_0279_11302017", "Q_0279_12052019", "Q_0279_12132016", "Q_0285_03212017", "Q_0285_06062018", "Q_0286_03212017", "Q_0287_06062018", "Q_0289_03212017", "Q_0289_06062018", "Q_0291_11042016", "Q_0291_11302018", "Q_0304_12202016", "Q_0310_01252018", "Q_0310_02132017", "Q_0310_04292019", "Q_0319_03192018", "Q_0319_03282017", "Q_0321_03192018", "Q_0321_03272017", "Q_0324_04182018", "Q_0326_10202017", "Q_0326_12062018", "Q_0327_10192017", "Q_0327_12072018", "Q_0331_06102019", "Q_0331_06212018", "Q_0331_06272017", "Q_0333_04142017", "Q_0334_12012016", "Q_0336_01102017", "Q_0345_04122017", "Q_0345_08152018", "Q_0345_09112019", "Q_0346_04102017", "Q_0346_04102018", "Q_0348_04212017", "Q_0348_08152018", "Q_0350_04192017", "Q_0350_09142018", "Q_0353_04182018", "Q_0353_05022017", "Q_0355_05312018", "Q_0356_05312018", "Q_0361_10212019", "Q_0361_11202018", "Q_0369_04182018", "Q_0369_06182019", "Q_0371_08042020", "Q_0374_05252018", "Q_0381_08072018", "Q_0381_09102019", "Q_0382_08282018", "Q_0383_08282018", "Q_0387_08242018", "Q_0387_12032019", "Q_0390_09042018", "Q_0390_09302019", "Q_0391_09252018", "Q_0395_11062018", "Q_0397_10172019", "Q_0402_01112019", "Q_0404_03112019", "Q_0407_06122019", "Q_0408_05172019", "Q_0414_07172019", "Q_0415_07292019", "Q_0416_07292019", "Q_0425_11052019", "Q_0429_01092020", "Q_0432_02142020", "Q_0433_02262020", "Q_0443_06282021", "Q_0446_06152021", "Q_0459_08192021", "Q_0461_09112021", "Q_0484_01042022", "Q_0519_05312022", "Q_0520_06012022", "Q_0521_05202022", "Q_0525_06072022", "Q_0526_06242022", "Q_0527_07112022", "Q_0528_07202022", "Q_0529_07202022", "Q_0561_11032022", "Q_0568_10252022")
# exclude Q_0390_09302019 for now due to no AP BOLD, and exclude two NAPLS subjects with no demographic info and 02_S0013_00 with some NAs in NetHo data (need to investigate further)
# exclude the following NAPLS sessions after T1w QC (12/11/23)
# 04_S0115_00
# 06_S0068_00
# 01_S0040_00
# 01_S0045_03
# 08_S0052_00
# 01_S0064_00
# 01_S0072_00
# 04_S0115_00
# 08_S0052_00
# 01_S0064_00
exclude_sessions <- c("Q_0390_09302019","01_S0083_00","01_S0128_00","02_S0013_00","04_S0115_00","06_S0068_00","01_S0040_00","01_S0045_03","08_S0052_00","01_S0064_00","01_S0072_00","04_S0115_00","08_S0052_00","01_S0064_00")

# for now also exclude several new sessions without rsfa calculated
#exclude_sessions <- c("Q_0214_05012017","Q_0390_09302019","Q_0477_01052022","Q_0484_01042022","Q_0508_06232022","Q_0519_05312022","Q_0520_06012022","Q_0521_05202022","Q_0525_06072022","Q_0526_06242022","Q_0527_07112022","Q_0528_07202022","Q_0529_07202022","Q_0541_07182022","Q_0549_10182022","Q_0561_11032022","Q_0568_10252022")
prisma_sessions <- prisma_sessions[! prisma_sessions %in% exclude_sessions]
suny_sessions <- list.files(suny_dir,pattern="X[0-9]")
iop_sessions <- list.files(iop_dir,pattern="GQAIMS[0-9]")
rome_sessions <- c(list.files(rome_dir, pattern="C[0-9]"),list.files(rome_dir, pattern="D[0-9]"))
#napls_sessions <- list.files(napls_dir,pattern="[0-9]_")
# get only baseline napls
napls_sessions <- list.files(napls_dir,pattern="_00$")
napls_sessions <- napls_sessions[! napls_sessions %in% exclude_sessions]

all_sessions <- c(trio_sessions,prisma_sessions,suny_sessions,rome_sessions,iop_sessions, napls_sessions)

# read multisite demo table
#demo_multisite <- read.csv(file.path(project,"demographics/multisite/22q_multisite_demo_f31.csv"))
demo_multisite <- read.csv(file.path(project,"demographics/multisite/22q_multisite_demo.csv"))
# exclude listed sessions if any are in list
#demo_multisite <- demo_multisite[! demo_multisite$MRI_S_ID %in% exclude_sessions,]
# include only subject with mri
demo_multisite <- filter(demo_multisite, MRI_S_ID %in% all_sessions)
# subset to baseline
demo_multisite_bl <- filter(demo_multisite, visit_index==1)
# filter age
demo_multisite_bl <- filter(demo_multisite_bl, AGE >= 8 & AGE <= 45)

# read NAPLS baseline demographics
demo_napls_bl <- read.csv(file.path(project,"demographics/NAPLS/NAPLS_ClientInfo_13Jan2016nocommas.csv"))
# match napls MRI_S_IDs to demo table
napls_id_split <- strsplit(napls_sessions, split="_") %>% do.call(rbind,.) %>% as.data.frame
napls_id_split$MRI_S_ID <- napls_sessions
napls_id_bl <- filter(napls_id_split, V3=="00")
napls_id_match <- data.frame(MRI_S_ID=napls_id_bl$MRI_S_ID, SiteNumber=as.numeric(napls_id_bl$V1), SubjectNumber=as.numeric(gsub("S","",napls_id_bl$V2)))
# merge with demo
demo_napls_id <- merge(x=demo_napls_bl, y=napls_id_match, by=c("SiteNumber","SubjectNumber"), all.y=TRUE)

# make df with basic demographics across all 22q and NAPLS
# first add napls data
demo_napls=data.frame(MRI_S_ID=demo_napls_id$MRI_S_ID,
                      Group=demo_napls_id$SubjectType,
                      AGE=demo_napls_id$demo_age_ym,
                      SEX=demo_napls_id$demo_sex,
                      Site=demo_napls_id$SiteNumber)
demo_napls$Site <- paste0("NAPLS",demo_napls$Site)
demo_napls$SEX <-  factor(demo_napls$SEX,levels=c(1,2),labels=c("M","F"))
demo_napls$Group <- factor(demo_napls$Group,levels=c("Prodromal","Control"),labels=c("CHR","CONTROL-N"))
# then add 22q data
demo_22q=data.frame(MRI_S_ID=demo_multisite_bl$MRI_S_ID,
                      Group=demo_multisite_bl$SUBJECT_IDENTITY,
                      AGE=demo_multisite_bl$AGE,
                      SEX=demo_multisite_bl$SEX,
                      Site=demo_multisite_bl$Site)
demo_22q$SEX <-  factor(demo_22q$SEX,levels=c("M","F"),labels=c("M","F"))
demo_22q$Group <- factor(demo_22q$Group,levels=c("PATIENT-DEL","CONTROL"),labels=c("22qDel","CONTROL"))
# combine
demo_22q_napls <- rbind(demo_22q, demo_napls)
# get age squared column for regression
demo_22q_napls$AGE2 <- (demo_22q_napls$AGE)^2
```

add converter label for NAPLS2
```{r convertLabel}
converters <- read_xlsx(file.path(project,"demographics/NAPLS/converters.xlsx"))
convert_ids <- merge(x=converters, y=napls_id_match, by=c("SiteNumber","SubjectNumber"))
demo_22q_napls$GroupConvert <- as.character(demo_22q_napls$Group)
demo_22q_napls[which(demo_22q_napls$MRI_S_ID %in% convert_ids$MRI_S_ID),"GroupConvert"] <- "CHRc"
demo_22q_napls$GroupConvert %<>% as.factor
```

load movement data
```{r loadMovement}
## get movement info
# function to get mapping between boldn and run name from session_hcp.txt
get_boldn_names <- function(sesh,sessions_dir){
  hcptxt <- read.table(file.path(sessions_dir,sesh,"session_hcp.txt"),sep=":",comment.char="#",fill=T,strip.white=T,col.names=c(1:4)) %>% as.data.frame()
  hcpbolds <- hcptxt %>% filter(grepl("bold[0-9]",X2))
  df_out <- cbind(rep(sesh,times=nrow(hcpbolds)),hcpbolds$X2,hcpbolds$X3)
  colnames(df_out) <- c("sesh","bold_n","bold_name")
  return(df_out)
}

# function to get %udvarsme from images/functional/movement/boldn.scrub
get_percent_udvarsme <- function(sesh,sessions_dir,bold_name_use){
  mov_dir <- file.path(sessions_dir,sesh,"images/functional/movement")
  sesh_bolds <- get_boldn_names(sesh=sesh,sessions_dir=sessions_dir) %>% as.data.frame %>% filter(bold_name == bold_name_use)
  if(nrow(sesh_bolds) > 0){
    boldns_use <- sesh_bolds$bold_n %>% as.vector
    for(i in 1:length(boldns_use)){
      boldn <- boldns_use[i] %>% as.character
      boldn_path <- file.path(mov_dir,paste(boldn,".scrub",sep=""))
      mov_scrub <- read.table(boldn_path, header=T)
      percent_udvarsme <- (sum(mov_scrub$udvarsme == 1)/length(mov_scrub$udvarsme)*100) %>% as.numeric %>% signif(3)
      percent_use <- (sum(mov_scrub$udvarsme == 0)/length(mov_scrub$udvarsme)*100) %>% as.numeric %>% signif(3)
      df_out <- cbind(sesh,boldn,bold_name_use,percent_udvarsme,percent_use)
      colnames(df_out) <- c("sesh","bold_n","bold_name","percent_udvarsme","percent_use")
      return(df_out)
    }
  }
}

# get trio movement
percent_udvarsme_trio <- lapply(trio_sessions,function(s) get_percent_udvarsme(sesh=s,sessions_dir=trio_dir,bold_name_use="resting")) %>% do.call(rbind,.) %>% as.data.frame
# get prisma movement
percent_udvarsme_prisma <- lapply(prisma_sessions,function(s) get_percent_udvarsme(sesh=s,sessions_dir=prisma_dir,bold_name_use="restingAP")) %>% do.call(rbind,.) %>% as.data.frame
# get rome movement
percent_udvarsme_rome <- lapply(rome_sessions,function(s) get_percent_udvarsme(sesh=s,sessions_dir=rome_dir,bold_name_use="resting")) %>% do.call(rbind,.) %>% as.data.frame
# get suny movement
percent_udvarsme_suny <- lapply(suny_sessions,function(s) get_percent_udvarsme(sesh=s,sessions_dir=suny_dir,bold_name_use="resting")) %>% do.call(rbind,.) %>% as.data.frame
# get iop movement
percent_udvarsme_iop <- lapply(iop_sessions,function(s) get_percent_udvarsme(sesh=s,sessions_dir=iop_dir,bold_name_use="resting")) %>% do.call(rbind,.) %>% as.data.frame
# get NAPLS movement
percent_udvarsme_napls <- lapply(napls_sessions,function(s) get_percent_udvarsme(sesh=s,sessions_dir=napls_dir,bold_name_use="RESTING")) %>% do.call(rbind,.) %>% as.data.frame

# combine
percent_udvarsme_all <- rbind(percent_udvarsme_trio,percent_udvarsme_prisma,percent_udvarsme_rome,percent_udvarsme_suny,percent_udvarsme_iop, percent_udvarsme_napls)
percent_udvarsme_all$percent_udvarsme <- as.numeric(percent_udvarsme_all$percent_udvarsme)
percent_udvarsme_all$percent_use <- as.numeric(percent_udvarsme_all$percent_use)
percent_udvarsme_all$MRI_S_ID <- percent_udvarsme_all$sesh

# add movement to demo bl
demo_multisite_bl <- merge(x=demo_multisite_bl, y=percent_udvarsme_all[,c("MRI_S_ID","percent_udvarsme")], by="MRI_S_ID", all.x=TRUE)
demo_22q_napls <- merge(x=demo_22q_napls, y=percent_udvarsme_all[,c("MRI_S_ID","percent_udvarsme")], by="MRI_S_ID", all.x=TRUE)
```

demo table
```{r demoTable}
demo_22q_napls_all <- demo_22q_napls

demo_multisite_bl$Group <- factor(demo_multisite_bl$SUBJECT_IDENTITY,levels=c("PATIENT-DEL","CONTROL"),labels=c("22qDel","CONTROL"))
demo_multisite_bl$SEX <- factor(demo_multisite_bl$SEX, levels=c("M","F"))
demo_multisite_bl$cardiac <- factor(demo_multisite_bl$cardiac, levels=c(0,1), labels=c("N","Y"))

#demo_22q_all <- filter(demo_22q_napls_all, Group %in% c("22qDel", "CONTROL")) %>% droplevels
demo_napls_all <- filter(demo_22q_napls_all, Group %in% c("CHR", "CONTROL-N")) %>% droplevels
demo_napls_all$conversion <- "N"
demo_napls_all[which(demo_napls_all$MRI_S_ID %in% convert_ids$MRI_S_ID), "conversion"] <- "Y"
demo_napls_all$conversion %<>% as.factor

# napls IQ
napls_neuro <- read_xlsx(file.path(project,"demographics/NAPLS_Neuro_30Jan2018.xlsx"),trim_ws=T, na=c("","NA"), col_names=T)
napls_neuro1 <- napls_neuro[,c("SiteNumber", "SubjectNumber","VisitLabel","wasiiq")] %>% rename("IQ_full"="wasiiq")
napls_neuro_id <- merge(x=napls_neuro1, y=napls_id_match, by=c("SiteNumber","SubjectNumber"))
demo_napls_all <- merge(x=demo_napls_all, y=napls_neuro_id, by="MRI_S_ID")

# napls meds
napls_meds <- read_xlsx(file.path(project,"demographics/NAPLS2MedsExtraction060616SOPSdatesV1toV7FINALSUMMARY.xlsx"),trim_ws=T, na=c("","NA","#NULL!"), col_names=T)
napls_meds_use <- napls_meds[,c("SiteNumber","SubjectNumber","Index1_current_AP")]
napls_meds_use$Med_Antipsychotic <- factor(napls_meds_use$Index1_current_AP, levels=c(0,1,99), labels=c("N","Y","N"))
demo_napls_all <- merge(x=demo_napls_all, y=napls_meds_use, by=c("SiteNumber","SubjectNumber"))

demo_table_22q <- CreateTableOne(data=demo_multisite_bl, strata="Group", vars=c("AGE","SEX","percent_udvarsme","Med_Antipsychotic","psych_dx", "IQ_full", "cardiac"))
demo_table_22q

demo_table_napls <- CreateTableOne(data=demo_napls_all, strata="Group", vars=c("AGE","SEX","percent_udvarsme","Med_Antipsychotic","conversion","IQ_full"))
demo_table_napls

# print tables
demo_table_22q_f <- print(demo_table_22q, showAllLevels = F, test=T,quote=F, contDigits=1)
demo_table_n_f <- print(demo_table_napls, showAllLevels = F, test=T,quote=F, contDigits=1)
demo_table_n_f <- rbind(demo_table_n_f,"-")
demo_table_all <- cbind(demo_table_22q_f[,c("22qDel","CONTROL","p")],demo_table_n_f[,c("CHR","CONTROL-N","p")])
colnames(demo_table_all) <- c("22qDel","Control22q","p-val-22q","CHR","ControlCHR","p-val-CHR")
rownames(demo_table_all) <- c("n",
                              "Age, Years, Mean (SD)",
                              "Sex, Female, n (%)",
                              "fMRI movement, Mean (SD)",
                              "Antipsychotic med, n (%)",
                              "Psychosis diagnosis, n (%)",
                              "Full Scale IQ, Mean (SD)",
                              "Congenital cardiac diagnosis, n (%)")
demo_table_all %<>% as.data.frame

# use gt() to make table for export
# instructions for bolding specific headers https://gt.rstudio.com/reference/tab_style.html
demo_table_out <- demo_table_all %>% gt(rownames_to_stub=TRUE) %>% 
  tab_style(style = cell_text(weight = "bold"),locations = list(cells_stub(), cells_column_labels())) %>%
  cols_align(align="right", columns=everything())

if(save_outputs==TRUE){
  gtsave(demo_table_out, filename = file.path(project,"figures/demographics/table1.png"))
  gtsave(demo_table_out, filename = file.path(project,"figures/demographics/table1.docx"))
}
```

load fMRI data
```{r loadFMRI}
# read CSV results
# function to read parcellated results and add columns for roi pair name, site, and ID 
read_csv_results <- function(sdir, fname, sesh, site){
  input <- read.csv(file.path(sdir,sesh,"images/functional",fname))
  session <- rep(sesh, times=nrow(input)) %>% as.data.frame
  site <- rep(site, times=nrow(input)) %>% as.data.frame
  new_cols <- cbind(session,site)
  colnames(new_cols) <- c("MRI_S_ID","site")
  output <- cbind(input,new_cols)
  return(output)
}

## file name to look for
# RSFA
rsfa_name <- "resting_parcellated_voxel_RSFA_Atlas_s_hpss_res-mVWMWB1d_lpss_whole_brain_CABNP.csv"
rsfa_name_prisma <- "restingAP_parcellated_voxel_RSFA_Atlas_s_hpss_res-mVWMWB1d_lpss_whole_brain_CABNP.csv"
rsfa_name_napls <- "RESTING_parcellated_voxel_RSFA_Atlas_s_hpss_res-mVWMWB1d_lpss_whole_brain_CABNP.csv"

# local connectivity
netho_name <- "resting_ParcelNetHo_Atlas_s_hpss_res-mVWMWB1d_lpss_whole_brain_CABNP.csv"
netho_name_prisma <- "restingAP_ParcelNetHo_Atlas_s_hpss_res-mVWMWB1d_lpss_whole_brain_CABNP.csv"
netho_name_napls <- "RESTING_ParcelNetHo_Atlas_s_hpss_res-mVWMWB1d_lpss_whole_brain_CABNP.csv"

# between parcel connectivity
bparc_name <- "resting_fc_matrix_Atlas_s_hpss_res-mVWMWB1d_lpss_CABNP_between_parcel.csv"
bparc_name_prisma <- "restingAP_fc_matrix_Atlas_s_hpss_res-mVWMWB1d_lpss_CABNP_between_parcel.csv"
bparc_name_napls <- "RESTING_fc_matrix_Atlas_s_hpss_res-mVWMWB1d_lpss_CABNP_between_parcel.csv"

# read rsfa
trio_rsfa <- lapply(filter(demo_multisite_bl, Site=="UCLAtrio")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="UCLAtrio",sdir=trio_dir,fname=rsfa_name)) %>% do.call(rbind,.)
prisma_rsfa <- lapply(filter(demo_multisite_bl, Site=="UCLAprisma")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="UCLAprisma",sdir=prisma_dir,fname=rsfa_name_prisma)) %>% do.call(rbind,.)
suny_rsfa <- lapply(filter(demo_multisite_bl, Site=="SUNY")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="SUNY",sdir=suny_dir,fname=rsfa_name)) %>% do.call(rbind,.)
rome_rsfa <- lapply(filter(demo_multisite_bl, Site=="Rome")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="Rome",sdir=rome_dir,fname=rsfa_name)) %>% do.call(rbind,.)
iop_rsfa <- lapply(filter(demo_multisite_bl, Site=="IoP")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="IoP",sdir=iop_dir,fname=rsfa_name)) %>% do.call(rbind,.)
napls_rsfa <- lapply(napls_sessions, function(s) read_csv_results(sesh=s,site="NAPLS2",sdir=napls_dir,fname=rsfa_name_napls)) %>% do.call(rbind,.)

rsfa_all <- rbind(trio_rsfa,prisma_rsfa,suny_rsfa,rome_rsfa,iop_rsfa,napls_rsfa)
rsfa_all$INDEX %<>% as.numeric
rsfa_all$t_sd %<>% as.numeric
rsfa_all$t_mean %<>% as.numeric

# read local connectivity
trio_netho <- lapply(filter(demo_multisite_bl, Site=="UCLAtrio")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="UCLAtrio",sdir=trio_dir,fname=netho_name)) %>% do.call(rbind,.)
prisma_netho <- lapply(filter(demo_multisite_bl, Site=="UCLAprisma")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="UCLAprisma",sdir=prisma_dir,fname=netho_name_prisma)) %>% do.call(rbind,.)
suny_netho <- lapply(filter(demo_multisite_bl, Site=="SUNY")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="SUNY",sdir=suny_dir,fname=netho_name)) %>% do.call(rbind,.)
rome_netho <- lapply(filter(demo_multisite_bl, Site=="Rome")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="Rome",sdir=rome_dir,fname=netho_name)) %>% do.call(rbind,.)
iop_netho <- lapply(filter(demo_multisite_bl, Site=="IoP")$MRI_S_ID, function(s) read_csv_results(sesh=s,site="IoP",sdir=iop_dir,fname=netho_name)) %>% do.call(rbind,.)
napls_netho <- lapply(napls_sessions, function(s) read_csv_results(sesh=s,site="NAPLS2",sdir=napls_dir,fname=netho_name_napls)) %>% do.call(rbind,.)

netho_all <- rbind(trio_netho,prisma_netho,suny_netho,rome_netho,iop_netho,napls_netho)
netho_all$INDEX %<>% as.numeric
netho_all$NetHo %<>% as.numeric

# function to convert parcellated fc matrix to global fc by getting the average connectivity for each ROI
gbc_from_matrix <- function(mat, col1="roi_1", col2="roi_2", variable="pearson_r_Fz", rois=1:360, key=ji_key){
  # deprecated line below getting unique rois in favor of choosing rois in function input for more flexibility, with default rois 1:360 (e.g. cortex)
  #rois <- unique(c(mat[,col1],mat[,col2]))
  # make df to filter (rename chosen columns to "col1" and "col2" to easily reference in filter command)
  dat <- mat
  dat$col1 <- dat[,col1]
  dat$col2 <- dat[,col2]
  dat[,variable] %<>% as.numeric
  # filter for only specified rois (default only cortex)
  dat_use <- filter(dat, col1 %in% rois & col2 %in% rois)[,c("MRI_S_ID","site","col1","col2",variable)]
  # get subject ID and site
  id <- unique(dat_use$MRI_S_ID)
  site <- unique(dat_use$site)
  if(length(id)>1){
    stop("Error: more than one MRI ID in input data")
  }
  # make output df with one row per roi
  out <- data.frame(INDEX=rois)
  # get mean fc for each roi
  for(r in rois){
    rows <- filter(dat_use, col1==r | col2==r)
    gbc <- mean(rows[,variable]) 
    out[which(out$INDEX==r),"GBC"] <- gbc
  }
  out <- merge(x=out, y=key, by="INDEX", all.y=TRUE)
  out$MRI_S_ID <- id
  out$site <- site
  return(out)
}

# read between parcel fc CORTEX
trio_gbc <- lapply(filter(demo_multisite_bl, Site=="UCLAtrio")$MRI_S_ID, function(s) gbc_from_matrix(mat=read_csv_results(sesh=s,site="UCLAtrio",sdir=trio_dir,fname=bparc_name))) %>% do.call(rbind,.)

prisma_gbc <- lapply(filter(demo_multisite_bl, Site=="UCLAprisma")$MRI_S_ID, function(s) gbc_from_matrix(mat=read_csv_results(sesh=s,site="UCLAprisma",sdir=prisma_dir,fname=bparc_name_prisma))) %>% do.call(rbind,.)

suny_gbc <- lapply(filter(demo_multisite_bl, Site=="SUNY")$MRI_S_ID, function(s) gbc_from_matrix(mat=read_csv_results(sesh=s,site="SUNY",sdir=suny_dir,fname=bparc_name))) %>% do.call(rbind,.)

rome_gbc <- lapply(filter(demo_multisite_bl, Site=="Rome")$MRI_S_ID, function(s) gbc_from_matrix(mat=read_csv_results(sesh=s,site="Rome",sdir=rome_dir,fname=bparc_name))) %>% do.call(rbind,.)

iop_gbc <- lapply(filter(demo_multisite_bl, Site=="IoP")$MRI_S_ID, function(s) gbc_from_matrix(mat=read_csv_results(sesh=s,site="IoP",sdir=iop_dir,fname=bparc_name))) %>% do.call(rbind,.)

napls_gbc <- lapply(napls_sessions, function(s) gbc_from_matrix(mat=read_csv_results(sesh=s,site="NAPLS2",sdir=napls_dir,fname=bparc_name_napls))) %>% do.call(rbind,.)

gbc_all <- rbind(trio_gbc,prisma_gbc,suny_gbc,rome_gbc,iop_gbc,napls_gbc)
gbc_all$INDEX %<>% as.numeric
gbc_all$GBC %<>% as.numeric
```

Notes on NAPLS QC: 
multiple things to fix in input data
NetHo data initially had NAs as well as inf values
- NA in all "Frontoparietal-29_R-Cerebellum" and "Visual1-04_R-Accumbens" --> check size?
- several subjects have multiple NA (those excluded for short BOLDs marked with *):
  - 02_S0077_00 (700) *
  - 08_S0081_00 (362) *
  - 01_S0074_00 (166) *
  - 08_S0057_00 (11) *
  - 02_S0013_00 (5) - structural QC looks OK
  - 03_S0122_00 (5) - structural QC missing regions including parts of temporal lobe
- several subjects have infinite NetHo values for multiple parcels, and all overlap with cases with multiple NAs
  - 01_S0074_00 (157) *
  - 02_S0077_00 (11) *
  - 08_S0057_00 (141) *
  - 08_S0081_00 (130) *
02_S0077_00 GBC is NA for all parcels *

get info about netho NA parcels
```{r nethoInfo}
# ged indices
r1 <- filter(ji_key, LABEL=="Frontoparietal-29_R-Cerebellum")$INDEX
r2 <- filter(ji_key, LABEL=="Visual1-04_R-Accumbens")$INDEX
#
which(xii_Ji_parcel$data$subcort==r1)
which(xii_Ji_parcel$data$subcort==r2)
# both ROIs assigned NA in NetHo analysis have one single voxel and thus can not calculate NetHo
# need to remove NA rows without disrupting 

# filter NAs from NetHo
netho_no_na <- filter(netho_all, !is.na(NetHo))
```
  
save workspace with initial data
```{r saveInit, paged.print=FALSE}
# save image
if(save_outputs==TRUE){
  # save list of packages
  setwd(project)
  sink("package_versions.txt")
  sessionInfo()
  sink()

  save.image(file=file.path(project,"demographics/22q_chr_fmri_init_ctx.Rdata"),compress = "bzip2")
}
```

harmonize sites with neurocombat
need to harmonize separately for each measure (rsfa, local connectivity, global connectivity)
```{r neuroComBat, message=FALSE, warning=FALSE, paged.print=FALSE}
# function to run neurocombat (includes study defaults)
run_neurocombat <- function(input, 
                            var_column, 
                            site_column="Site",
                            formula="INDEX ~ MRI_S_ID",
                            covars=c("Group","AGE","AGE2","SEX","percent_udvarsme"),
                            model="~Group + AGE + AGE2 + SEX + percent_udvarsme",
                            #covars=c("AGE","AGE2","SEX","percent_udvarsme"),
                            #model="~AGE + AGE2 + SEX + percent_udvarsme",
                            index_col="INDEX", 
                            id_col="MRI_S_ID", 
                            demo=demo_22q_napls){
  # remove site column from input and replace with demo
  input <- subset(input, select=-site)
  input <- merge(x=input, y=demo[,c("MRI_S_ID","Site")], by="MRI_S_ID", all.x=TRUE)
  # get list of indices
  indices <- unique(input$INDEX)
  # cast to wide so that rows are parcel indices and columns are MRI_S_IDs
  data.table::setDT(input)
  input_subcols <- reshape2::dcast(data=input, formula=formula, value.var=var_column) 
  # get subject ids in order of columns
  subcols <- which(names(input_subcols)!= index_col)
  subnames <- names(input_subcols)[subcols]

  # get covariates from multisite baseline demo df, ordered the same as subject ID columns for input to neurocombat
  covardf <- merge(x=data.frame(subnames), y=demo[,c(covars,site_column,id_col)], by.x="subnames", by.y=id_col, all.x=TRUE)
  # drop unused groups to avoid unnecessary factors in model
  covardf$Group %<>% droplevels()
  
  # run neurocombat for parcellated RSFA with site as batch variable and AGE and SEX included in the model
  # using default parametric model (this paper shows parametric prior estimates outperform non-parametric in neurocombat: https://www.sciencedirect.com/science/article/pii/S2666956022000605)
  #model_matrix <- model.matrix(~covardf$AGE + covardf$AGE2 + covardf$SEX + covardf$percent_udvarsme)
  model_matrix <- model.matrix(formula(model),data=covardf[covars])
  #print(summary(as.factor(covardf[,site_column])))
  combat <- neuroCombat(dat=input_subcols[,subcols], batch=covardf[,site_column], mod=model_matrix, parametric=TRUE, eb=TRUE, verbose=FALSE)
  
  # convert combat results  back to long df
  combat_d <- combat$dat.combat %>% as.data.frame
  data.table::setDT(combat_d)
  combat_d$INDEX <- indices
  combat_d$INDEX %<>% as.numeric
  combat_l <- melt.data.table(combat_d, id.vars="INDEX") %>% rename("MRI_S_ID"="variable")
  # merge with input data
  out <- merge(x=input, y=combat_l, by=c("INDEX", "MRI_S_ID"), all.x=TRUE, all.y=TRUE)
  return(out)
}

# use only cortical regions
rsfa_ctx <- filter(rsfa_all, INDEX %in% 1:360)
netho_ctx <- filter(netho_no_na, INDEX %in% 1:360)
gbc_ctx <- filter(gbc_all, INDEX %in% 1:360)

# run combat
rsfa_combat_22q <- run_neurocombat(input=filter(rsfa_ctx, site %in% c("UCLAtrio","UCLAprisma","SUNY","Rome","IoP" )), var_column="t_sd")
rsfa_combat_napls <- run_neurocombat(input=filter(rsfa_ctx, site=="NAPLS2"), var_column="t_sd")
#rsfa_combat <- rbind(rsfa_combat_22q,rsfa_combat_napls)

netho_combat_22q <- run_neurocombat(input=filter(netho_ctx, site %in% c("UCLAtrio","UCLAprisma","SUNY","Rome","IoP" )), var_column="NetHo")
netho_combat_napls <- run_neurocombat(input=filter(netho_ctx, site=="NAPLS2"), var_column="NetHo")
#netho_combat <- rbind(netho_combat_22q,netho_combat_napls)

gbc_combat_22q <- run_neurocombat(input=filter(gbc_ctx, site %in% c("UCLAtrio","UCLAprisma","SUNY","Rome","IoP" )), var_column="GBC")
gbc_combat_napls <- run_neurocombat(input=filter(gbc_ctx, site=="NAPLS2"), var_column="GBC")
#gbc_combat <- rbind(gbc_combat_22q,gbc_combat_napls)

#netho_combat <- run_neurocombat(input=netho_no_na, var_column="NetHo")
#gbc_combat <- run_neurocombat(input=gbc_all, var_column="GBC")

```

normalize based on control group
```{r normalize, message=FALSE, warning=FALSE, paged.print=FALSE}
# function to get mean and standard dev of hcs for a given parcel to use for normalization
# takes as input, a long data frame e.g. gbc_combat, vectors of control IDs, and the desired parcel index 
get_hc_stats <- function(df, hcs_ids, parc){
  dfh <- filter(df, MRI_S_ID %in% hcs_ids & INDEX == parc)
  m <- mean(as.numeric(dfh$value))
  s <- sd(as.numeric(dfh$value))
  out <- data.frame(parcel_hc_mean=m, parcel_hc_sd=s)
  return(out)
}

# function to normalize based on hc mean and sd
hc_normalize <- function(df, hcs_ids){
  # first get hc stats for all parcels
  inds <- unique(df$INDEX)
  hc_stats <- lapply(inds, function(p) get_hc_stats(parc=p, df=df, hcs_ids=hcs_ids)) %>% do.call(rbind,.)
  hc_stats$INDEX <- inds
  # then merge parcel norms with full df
  dfn <- merge(x=df, y=hc_stats, by="INDEX", all.x=TRUE)
  # normalize data in each parcel based on control mean and sd for that parcel
  dfn$value_normed <- (dfn$value - dfn$parcel_hc_mean)/dfn$parcel_hc_sd
  return(dfn)
}

# get list of all controls
hc_ids <- filter(demo_22q_napls, Group=="CONTROL")$MRI_S_ID
hcn_ids <- filter(demo_22q_napls, Group=="CONTROL-N")$MRI_S_ID

# normalize each measure
rsfa_norm_22q <- hc_normalize(df=rsfa_combat_22q, hcs_ids=hc_ids)
rsfa_norm_napls <- hc_normalize(df=rsfa_combat_napls, hcs_ids=hcn_ids)
rsfa_norm <- rbind(rsfa_norm_22q, rsfa_norm_napls)

netho_norm_22q <- hc_normalize(df=netho_combat_22q, hcs_ids=hc_ids)
netho_norm_napls <- hc_normalize(df=netho_combat_napls, hcs_ids=hcn_ids)
netho_norm <- rbind(netho_norm_22q,netho_norm_napls)

gbc_norm_22q <- hc_normalize(df=gbc_combat_22q, hcs_ids=hc_ids)
gbc_norm_napls <- hc_normalize(df=gbc_combat_napls, hcs_ids=hcn_ids)
gbc_norm <- rbind(gbc_norm_22q,gbc_norm_napls)

```

plot pre/post combat
```{r plotComBat}
# function to plot pre and post combat
plot_combat <- function(df, raw_col, title=""){
  # get mean of all parcels per subject pre/post combat to look at distributions
  subs <- sort(unique(df$MRI_S_ID))
  sublist <- lapply(subs, function(s) data.frame(filter(df, MRI_S_ID==s)))
  precombat <- lapply(sublist, function(s) mean(s[,raw_col])) %>% do.call(rbind,.)
  postcombat <- lapply(sublist, function(s) mean(s$value)) %>% do.call(rbind,.)
  parc_means <- data.frame(MRI_S_ID=subs, postcombat=as.vector(postcombat), precombat=as.vector(precombat))
  # add site
  df$duplicated <- duplicated(df$MRI_S_ID)
  dup <- filter(df, duplicated==FALSE)[,c("MRI_S_ID","Site")]
  parc_means_demo <- merge(x=parc_means, y=dup, by="MRI_S_ID")
  parc_means_demo$Site %<>% as.factor
  print(nrow(parc_means))
  print(nrow(parc_means_demo))
  # plot meean RSFA distributions by site pre combat
  pl_precombat <- ggplot(parc_means_demo, aes(precombat, fill=Site, after_stat(count)))+
    geom_density(kernel="gaussian", alpha=0.5)+
    scale_fill_manual(values=rainbow(13))+
    theme_classic()+
    ggtitle(paste("pre-combat",title))
  
  # plot meean RSFA distributions by site post combat
  pl_postcombat <- ggplot(parc_means_demo, aes(postcombat, fill=Site, after_stat(count)))+
    geom_density(kernel="gaussian", alpha=0.5)+ 
    scale_fill_manual(values=rainbow(13))+
    theme_classic()+
    ggtitle(paste("post-combat",title))
  
  ggarrange(pl_precombat,pl_postcombat, nrow=1, common.legend=T,legend="right")
}

plot_normed <- function(df, name){
  # get mean of all parcels per subject pre/post combat to look at distributions
  subs <- sort(unique(df$MRI_S_ID))
  sublist <- lapply(subs, function(s) data.frame(filter(df, MRI_S_ID==s)))
  values <- lapply(sublist, function(s) mean(s$value_normed)) %>% do.call(rbind,.)
  normed <- data.frame(MRI_S_ID=subs, normed=as.vector(values))
  # add site
  df$duplicated <- duplicated(df$MRI_S_ID)
  dup <- filter(df, duplicated==FALSE)[,c("MRI_S_ID","Site")]
  normed_demo <- merge(x=normed, y=dup, by="MRI_S_ID")
  normed_demo$Site %<>% as.factor
  print(nrow(normed_demo))
  print(nrow(normed_demo))
  # plot meean RSFA distributions by site post combat
  pl_postcombat <- ggplot(normed_demo, aes(normed, fill=Site, after_stat(count)))+
  geom_density(kernel="gaussian", alpha=0.5)+ 
  #scale_fill_manual(values=rainbow(13))+
  theme_classic()+
  ggtitle(paste(name,"normed"))
  return(pl_postcombat)
}

norm_plot_rsfa <- plot_normed(rsfa_norm, name="rsfa")
norm_plot_netho <- plot_normed(netho_norm, name="NetHo")
norm_plot_gbc <- plot_normed(gbc_norm, name="gbc")

combat_plot_rsfa <- plot_combat(df=rsfa_norm, raw_col="t_sd", title="RSFA")
combat_plot_netho <- plot_combat(df=netho_norm, raw_col="NetHo", title="NetHo")
combat_plot_gbc <- plot_combat(df=gbc_norm, raw_col="GBC", title="GBC")

norm_plot_rsfa
norm_plot_netho
norm_plot_gbc

combat_plot_rsfa
combat_plot_netho
combat_plot_gbc
```
convert normed combat results back to wide df merged with demographics
```{r demoComBat}
# function to convert long to wide df with indices (renamed to r_index) as columns
rows_to_cols <- function(results, demo, index_colname="INDEX"){
  df <- as.data.frame(results)
  # add prefix "r_" to parcel indices to use as column names in wide df 
  df$index_col <- paste0("r_",df[,index_colname])
  # cast to wide to merge with demographics
  dt <- data.table::setDT(df)
  # list of new column names
  parc_cols <- unique(dt$index_col)
  # make wide df with column from MRI_S_ID and one column per parcel with cells containing normed combat value
  dt_wide <- reshape2::dcast(dt, MRI_S_ID ~ index_col, value.var="value_normed") 
  # order cols
  dt_wide_order <- dt_wide[,c("MRI_S_ID", parc_cols)]
  # merge with demo table 
  dt_demo <- merge(x=demo, y=dt_wide_order, by="MRI_S_ID") 
  # return both the data frame and list of results columns
  out <- list(parcels=as.vector(parc_cols), df=as.data.frame(dt_demo))
  return(out)
}

# get list objects with vector of results column names and demo df merged to results
rsfa_wide <- rows_to_cols(results=rsfa_norm, demo=demo_22q_napls)
netho_wide <- rows_to_cols(results=netho_norm, demo=demo_22q_napls)
gbc_wide <- rows_to_cols(results=gbc_norm, demo=demo_22q_napls)
```

test linear models for 22q vs TD and CHR vs TD separately
```{r mainLM, message=FALSE, warning=FALSE, paged.print=FALSE}
# function to return beta coefficient for group in a lm predicting MRI from chosen predictors
lm_parcel_group_covars <- function(df, var, predictors, groups, groupcol, refgroup, test_out_model=FALSE){
  # create formula with var on left side and predictors string on right
  form <- reformulate(predictors,response=var)
  # test linear model
  lm <- lm(formula=form,data=df, na.action="na.omit")
  slm <- summary(lm)
  # get stats for main effect of group
  g <- groups[which(groups != refgroup)]
  gname <- paste0(groupcol,g)
  g_stats <- slm$coefficients[gname,] %>% t %>% as.data.frame
  colnames(g_stats) <- c("group_beta","group_se","group_t","group_p")
  # get stats for site effects
  srows <- grep("Site*", rownames(slm$coefficients))
  s_stats <- slm$coefficients[srows,]
  colnames(s_stats) <- c("beta","se","t","p")
  # convert rows to columns
  s_out <- data.frame()
  for(r in 1:nrow(s_stats)){
    rname <- rownames(s_stats)[r]
    cnames <- paste0(rname,"_",colnames(s_stats))
    s_out[1,cnames] <- s_stats[r,] 
  }
  # option to return full model instead of table for testing purposes
  if(test_out_model==TRUE){
    out <- lm
  }else{
    # add outputs together
    out <- cbind(g_stats,s_out)
  }
  return(out)
}
#test <- lm_parcel_group_covars(df=filter(rsfa_wide$df, Group %in% c("22qDel","CONTROL")), var="r_1",predictors="Group + AGE + AGE2 + SEX + Site + percent_udvarsme",groupcol="Group", groups=c("22qDel","CONTROL"), refgroup="22qDel") 

# function to apply lm at each parcel, expects list object output from rows_to_cols
# defaults, including formula predictors, are set in function but different values can be specified
# groups should be a vector specifying which groups should be ussed
get_parcel_group_lm <- function(list, 
                                groups, 
                                groupcol="Group", 
                                refgroup="CONTROL",
                                sitecol="Site",
                                refsite,
                                covars="AGE + AGE2 + SEX + Site + percent_udvarsme", 
                                alpha=0.05, 
                                roi_key=ji_key,
                                prefix="r_",
                                filter=FALSE,
                                filtercol="",
                                filterin=""){
  if(length(groups)!=2){ stop("Error: number of groups not equal to 2")}
  # add group to string of model variables
  predictors <- paste(groupcol, "+", covars)
  # filter by specified groups and relevel factor
  df_all <- as.data.frame(list$df)
  df_all$groupcol <- df_all[,groupcol]
  # filter data based to keep only rows wither value of filtercol is in filterin
  if(filter==TRUE){
    dff <- df_all %>% filter(.data[[filtercol]] %in% filterin)
  }else{
    dff <- df_all
  }
  # filter groupcol in groups
  df <- filter(dff, groupcol %in% groups)
  df[,groupcol] <- relevel(as.factor(df[,groupcol]), ref=refgroup)
  # relevel site
  df[,sitecol] <- relevel(as.factor(df[,sitecol]), ref=refsite)
  # do linear model for every parcel, FDR correct p-values, and create column of betas set to NA when not FDR significant
  parc_cols <- list$parcels
  stats <- lapply(parc_cols, function(v) lm_parcel_group_covars(var=v, df=df, predictors=predictors, groups=groups, groupcol=groupcol, refgroup=refgroup)) %>% do.call(rbind,.) %>% as.data.frame
  #colnames(stats) <- c("group_beta","group_se","group_t","group_p")
  stats$group_FDR_q <- p.adjust(stats$group_p, method="fdr")
  stats$group_FDR_sig <- stats$group_FDR_q < alpha
  stats$group_beta_FDR <- stats$group_beta
  stats$group_beta_FDR[which(stats$group_FDR_sig != TRUE)] <- NA
  # add index column and merge with roi key (assumes column named INDEX in roi_key)
  stats$indexcol <- parc_cols
  stats$INDEX <- gsub(prefix,"",stats$indexcol)
  out <- merge(x=roi_key, y=stats, by="INDEX", all.x=TRUE, all.y=TRUE)
  return(out)
}
#test <- get_parcel_group_lm(list=rsfa_wide, groups=c("22qDel","CONTROL"),refgroup="CONTROL", refsite="UCLAtrio", roi_key=filter(ji_key,INDEX %in% 1:360))

# get main effects of group for each measure
rsfa_22q_lms <- get_parcel_group_lm(list=rsfa_wide, groups=c("22qDel","CONTROL"), refgroup="CONTROL", refsite="UCLAtrio", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("RSFA 22q significant regions:",sum(rsfa_22q_lms$group_FDR_sig)))

rsfa_chr_lms <- get_parcel_group_lm(list=rsfa_wide, groups=c("CHR","CONTROL-N"), refgroup="CONTROL-N", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("RSFA CHR significant regions:",sum(rsfa_chr_lms$group_FDR_sig)))

netho_22q_lms <- get_parcel_group_lm(list=netho_wide, groups=c("22qDel","CONTROL"), refgroup="CONTROL", refsite="UCLAtrio", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("NetHo 22q significant regions:",sum(netho_22q_lms$group_FDR_sig, na.rm=TRUE)))

netho_chr_lms <- get_parcel_group_lm(list=netho_wide, groups=c("CHR","CONTROL-N"), refgroup="CONTROL-N", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("NetHo CHR significant regions:",sum(netho_chr_lms$group_FDR_sig, na.rm=TRUE)))

gbc_22q_lms <- get_parcel_group_lm(list=gbc_wide, groups=c("22qDel","CONTROL"), refgroup="CONTROL", refsite="UCLAtrio", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("GBC 22q significant regions:",sum(gbc_22q_lms$group_FDR_sig)))

gbc_chr_lms <- get_parcel_group_lm(list=gbc_wide, groups=c("CHR","CONTROL-N"), refgroup="CONTROL-N", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("GBC CHR significant regions:",sum(gbc_chr_lms$group_FDR_sig)))
```

test CHRc vs TD and CHRc vs CHR
```{r chrcLM}
# test CHRc vs CONTROL-N
rsfa_chrc_lms <- get_parcel_group_lm(list=rsfa_wide, groups=c("CHRc","CONTROL-N"), groupcol="GroupConvert", refgroup="CONTROL-N", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("RSFA CHRc vs Control significant regions:",sum(rsfa_chrc_lms$group_FDR_sig)))

netho_chrc_lms <- get_parcel_group_lm(list=netho_wide, groups=c("CHRc","CONTROL-N"), groupcol="GroupConvert", refgroup="CONTROL-N", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("NetHo CHRc vs Control significant regions:",sum(netho_chrc_lms$group_FDR_sig)))

gbc_chrc_lms <- get_parcel_group_lm(list=gbc_wide, groups=c("CHRc","CONTROL-N"), groupcol="GroupConvert", refgroup="CONTROL-N", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("GBC CHRc vs Control significant regions:",sum(gbc_chrc_lms$group_FDR_sig)))

# test CHRc vs CHR
rsfa_chrcchr_lms <- get_parcel_group_lm(list=rsfa_wide, groups=c("CHRc","CHR"), groupcol="GroupConvert", refgroup="CHR", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("RSFA CHRc vs CHR significant regions:",sum(rsfa_chrcchr_lms$group_FDR_sig)))

netho_chrcchr_lms <- get_parcel_group_lm(list=netho_wide, groups=c("CHRc","CHR"), groupcol="GroupConvert", refgroup="CHR", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("NetHo CHRc vs CHR significant regions:",sum(netho_chrcchr_lms$group_FDR_sig)))

gbc_chrcchr_lms <- get_parcel_group_lm(list=gbc_wide, groups=c("CHRc","CHR"), groupcol="GroupConvert", refgroup="CHR", refsite="NAPLS1", roi_key=filter(ji_key,INDEX %in% 1:360))
print(paste("GBC CHRc vs CHR significant regions:",sum(gbc_chrcchr_lms$group_FDR_sig)))
```

plot group difference maps
```{r funcPlotMRI, message=FALSE, warning=FALSE, paged.print=FALSE}
# function to take xifti atlas (with ROIs denoted by unique values) and return list of xifti matrix indices by brain structure for each ROI
get_roi_atlas_inds <- function(xii){
  # get all unique roi labels
  mxii <- as.matrix(xii)
  vals <- mxii %>% unique %>% sort %>% as.numeric
  # get brain structures to iterate through (cortex_left, cortex_right, subcort)
  xiinames <- names(xii$data)
  # for each ROI, get the indices for each brain structure
  # output is a nested list for each ROI (with "r_" added as prefix) and each brain structure, containing an array of xifti indices corresponding to the ROI in a given brain structure
  out <- lapply(setNames(vals,paste0("r_",vals)), function(v) lapply(setNames(xiinames,xiinames), function(n) which(xii$data[[n]] == v)))
  return(out)
}

# function to create xifti for plotting ROI values on a brain atlas
# input atlas xifti and data frame with at least two cols corresponding to ROI IDs (roi_col) and output values (val_col) e.g. gene expression or functional connectivity
# output modified atlas xifti with ROI IDs replaced with output values (for visualization)
atlas_xifti_new_vals <- function(xii, df, roi_col, val_col){
  # get list of xifti indices for each ROI
  inds <- get_roi_atlas_inds(xii)
  # create blank xii from atlas
  xii_out <- xii
  for (struct in names(xii_out$data)){
    if (!is.null(xii_out$data[[struct]])){
      xii_out$data[[struct]] <- as.matrix(rep(NA,times=nrow(xii_out$data[[struct]])))
    }
  }
  # create new column named roilabel from roi_col
  df$roilabel <- df[,roi_col]
  # for each roi in xii, set all relevant vertices to value from val_col based on roi_col
  for (roi in names(inds)){
    #print(roi)
    # get value for roi
    out_val <- as.numeric(filter(df[,c("roilabel",val_col)], roilabel==gsub("r_","",roi))[val_col])
    #print(out_val)
    # loop through brain structures, if ROI has any indices in a structure, set those to the output value
    for (struct in names(inds[[roi]])){
      roi_inds <- inds[[roi]][[struct]]
      l <- length(roi_inds)
      if (l > 0){
        xii_out$data[[struct]][roi_inds] <- out_val
      }
    }
  }
  return(xii_out)
}

# color pals for brain plots
# set up rcolorbrewer palettes
pal_red_yellow_blue <- function(){
  pal <- "RdYlBu"
  ncolors <- 1000
  mycolors <- rev(colorRampPalette(brewer.pal(11,pal))(ncolors))
  return(mycolors)
}

pal_red_blue <- function(){
  pal <- "RdBu"
  ncolors <- 1000
  mycolors <- rev(colorRampPalette(brewer.pal(11,pal))(ncolors))
  return(mycolors)
}

pal_yellow_orange_red <- function(){
  pal <- "YlOrRd"
  ncolors <- 1000
  mycolors <- colorRampPalette(brewer.pal(9,pal))(ncolors)
  return(mycolors)
}
```

```{r plotMRI}
# plot group difference beta only fdr<0.05
# 22q RSFA
pl_rsfa_22q_b_fdr <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=rsfa_22q_lms, roi_col="INDEX", val_col="group_beta_FDR")
view_xifti_surface(pl_rsfa_22q_b_fdr, title="Signal Variablity: 22qDel vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_rsfa_22q_b_fdr,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/rsfa_22q_b_fdr.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# 22q NetHo
pl_netho_22q_b_fdr <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=netho_22q_lms, roi_col="INDEX", val_col="group_beta_FDR")
view_xifti_surface(pl_netho_22q_b_fdr, title="Local Connectivity: 22qDel vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_netho_22q_b_fdr,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/netho_22q_b_fdr.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# 22q GBC
pl_gbc_22q_b_fdr <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=gbc_22q_lms, roi_col="INDEX", val_col="group_beta_FDR")
view_xifti_surface(pl_gbc_22q_b_fdr, title="Global Connectivity: 22qDel vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_gbc_22q_b_fdr,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/gbc_22q_b_fdr.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# plot group difference beta 
# 22q RSFA
pl_rsfa_22q_b <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=rsfa_22q_lms, roi_col="INDEX", val_col="group_beta")
view_xifti_surface(pl_rsfa_22q_b, title="Signal Variablity: 22qDel vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_rsfa_22q_b,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/rsfa_22q_b.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# 22q NetHo
pl_netho_22q_b <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=netho_22q_lms, roi_col="INDEX", val_col="group_beta")
view_xifti_surface(pl_netho_22q_b, title="Local Connectivity: 22qDel vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_netho_22q_b,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/netho_22q_b.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# 22q GBC
pl_gbc_22q_b <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=gbc_22q_lms, roi_col="INDEX", val_col="group_beta")
view_xifti_surface(pl_gbc_22q_b, title="Global Connectivity: 22qDel vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_gbc_22q_b,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/gbc_22q_b.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}
# plot CHR netho FDR beta
# chr NetHo
pl_netho_chr_b_fdr <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=netho_chr_lms, roi_col="INDEX", val_col="group_beta_FDR")
view_xifti_surface(pl_netho_chr_b_fdr, title="Local Connectivity: CHR vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_netho_chr_b_fdr,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/netho_chr_b_fdr.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# plot CHR threshold free beta
# chr RSFA
pl_rsfa_chr_b <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=rsfa_chr_lms, roi_col="INDEX", val_col="group_beta")
view_xifti_surface(pl_rsfa_chr_b, title="Signal Variablity: CHR vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_rsfa_chr_b,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/rsfa_chr_b.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# chr NetHo
pl_netho_chr_b <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=netho_chr_lms, roi_col="INDEX", val_col="group_beta")
view_xifti_surface(pl_netho_chr_b, title="Local Connectivity: CHR vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_netho_chr_b,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/netho_chr_b.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}

# chr GBC
pl_gbc_chr_b <- atlas_xifti_new_vals(xii=xii_Ji_parcel, df=gbc_chr_lms, roi_col="INDEX", val_col="group_beta")
view_xifti_surface(pl_gbc_chr_b, title="Global Connectivity: CHR vs TD (GSR)", cex.title=1.3,zlim=c(-0.8,0.8), colors=pal_red_blue())
# save
if(save_outputs==TRUE){
  view_xifti_surface(pl_gbc_chr_b,zlim=c(-0.8,0.8), colors=pal_red_blue(), fname=file.path(project,"figures/fmri_maps_GSR/gbc_chr_b.png"),legend_embed=FALSE, legend_fname = file.path(project,"figures/fmri_maps_GSR/legend.png"))
}
```

